# -*- coding: utf-8 -*-
"""Assignment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QctVNqtI-dP-lnONYWPr1cDVDRg6M3de

# Time Series Forecasting
"""

!pip install yfinance

import pandas as pd
import yfinance as yf

### If you are using colab, you can import google drive to save model checkpoints in a folder
from google.colab import drive
drive.mount('/content/drive/')
GDRIVE_PROJECT_PATH = '/content/drive/MyDrive/Colab-Notebooks/NLP'

# Fetching GameStop's stock data
df = yf.download('GME', start='2021-01-04', end='2021-12-31')
df = df.reset_index()

df.shape

df.tail(10)

import matplotlib.pyplot as plt


# Ensure the 'Date' column is in datetime format for proper plotting
df['Date'] = pd.to_datetime(df['Date'])

# Setting the plot size for better readability
plt.figure(figsize=(10, 6))

# Plotting the actual closing prices in the training period
plt.plot(df['Date'], df['Close'], label='Actual Close', color='blue', marker='o')

# Adding title and labels with font size adjustments
plt.title('Actual Closing Prices in Data', fontsize=16)
plt.xlabel('Date', fontsize=14)
plt.ylabel('Closing Price', fontsize=14)

# Rotating date labels for better visibility
plt.xticks(rotation=45)

# Adding a legend to distinguish the actual values
plt.legend()

# Display the plot
plt.tight_layout()
plt.show()

import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import LSTM, Dense
from pandas.tseries.holiday import USFederalHolidayCalendar
from pandas.tseries.offsets import CustomBusinessDay
from datetime import datetime, timedelta

# Convert 'Date' to datetime and sort the DataFrame just in case
df['Date'] = pd.to_datetime(df['Date']) # This line converts the 'Date' column of the DataFrame df to datetime objects.
df.sort_values('Date', inplace=True)
#  The .values attribute returns the data as a NumPy array. The .reshape(-1, 1) function changes
#  the shape of this array to ensure it has two dimensions, with one column and as many rows as necessary.
close_prices = df['Close'].values.reshape(-1, 1)
# Scale the data -> you can use any appropriate scaling methodology
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_close_prices = scaler.fit_transform(close_prices)

scaled_close_prices.shape

# Function to create sequences
def create_sequences(data, sequence_length):
    xs, ys = [], []
    for i in range(len(data) - sequence_length):
        x = data[i:(i + sequence_length)]
        y = data[i + sequence_length]
        xs.append(x)
        ys.append(y)
    return np.array(xs), np.array(ys)

SEQUENCE_LENGTH = 20  # You can adjust this value -> parameter tuning
X, y = create_sequences(scaled_close_prices, SEQUENCE_LENGTH)

print(X.shape)
print(y.shape)

# Split the data into training and test sets (train on data until May 31st)
TRAIN_END_DATE = '2021-05-31'
train_indices = df[df['Date'] <= TRAIN_END_DATE].index
X_train, y_train = X[:train_indices[-1]-SEQUENCE_LENGTH], y[:train_indices[-1]-SEQUENCE_LENGTH]

print(X_train.shape, y_train.shape)

"""
The model described is a neural network architecture using Long Short-Term Memory (LSTM) layers, commonly employed for sequence prediction problems such as time series forecasting. Here's a breakdown of each component of the model:

1. LSTM Layer with return_sequences=True
LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], 1)):
This is the first layer in the model and an LSTM layer with 50 units. LSTM units are a type of recurrent neural network (RNN) cell that are effective in capturing long-term dependencies in sequence data.
return_sequences=True indicates that this layer returns the full sequence of outputs for each sample. This is necessary when stacking LSTM layers so that the subsequent LSTM layer can receive sequences of data as input.
input_shape=(X_train.shape[1], 1) specifies the shape of the input data. In this context, X_train.shape[1] refers to the sequence length (number of time steps), and 1 refers to the number of features per time step. This model is configured to work with a single feature per time step, typical for univariate time series forecasting (e.g., predicting a stock price based on past values of the stock price alone).


2. LSTM Layer with return_sequences=False
LSTM(50, return_sequences=False):
This is the second LSTM layer in the model, also with 50 units.
return_sequences=False means this layer only returns the output for the last time step in the input sequence. This is used when the subsequent layer expects a single vector per sample rather than a sequence of vectors. Since the next layer is a dense layer (fully connected layer), only the final output of the LSTM is needed.
This layer serves to further process the information extracted by the first LSTM layer, focusing on extracting features that will be useful for the final prediction.


3. Dense Layer
Dense(1):
This is a fully connected layer that follows the LSTM layers. It has a single unit.
The purpose of this layer is to output a single value, which is the predicted value for the next time step in the sequence. For example, in stock price prediction, this would be the predicted stock price for the next day.
Since this model is likely intended for regression (predicting a continuous value), there's no activation function specified, implying a linear activation is used by default. This allows the model to output values in the range of the real numbers."""

# Define the LSTM model
model = Sequential([
    LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], 1)),
    LSTM(50, return_sequences=False),
    Dense(1)
])

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')

# Train the model
model.fit(X_train, y_train, epochs=20, batch_size=32)

business_days = pd.date_range(start=pd.to_datetime(TRAIN_END_DATE) + timedelta(days=1),
                              periods=66, freq='B')

business_days

# Get the last sequence from the training data
last_sequence = X_train[-1].reshape((1, SEQUENCE_LENGTH, 1))

# Create a list to hold predictions
predictions = []

# Predict future prices
for i in range(len(business_days)):
    # Get the prediction (scaled value)
    current_prediction = model.predict(last_sequence)[0]

    # Append the prediction
    predictions.append(current_prediction)

    # Update the sequence
    last_sequence = np.roll(last_sequence, -1, axis=1)
    last_sequence[0, -1, 0] = current_prediction

# Inverse transform the predictions to get actual values
predicted_prices = scaler.inverse_transform(np.array(predictions).reshape(-1, 1))

# Create a DataFrame with the predicted stock prices and dates
predictions_df = pd.DataFrame({
    'Date': business_days,
    'Predicted_Close': predicted_prices.flatten()
})

# Show the prediction results
print(predictions_df)

# Continue from the previous predictions_df creation code

# Ensure the 'Date' columns in both DataFrames are in the same format
df['Date'] = pd.to_datetime(df['Date'])
predictions_df['Date'] = pd.to_datetime(predictions_df['Date'])

# Merge the predictions with the actual closing prices from 'df'
predictions_with_actuals_df = predictions_df.merge(df[['Date', 'Close']], on='Date', how='left')

# Rename columns for clarity
predictions_with_actuals_df.rename(columns={'Close': 'Actual_Close'}, inplace=True)

# Show the DataFrame with predictions and actual closing prices
print(predictions_with_actuals_df)

# Continue from the previous predictions_df creation code

# Ensure the 'Date' columns in both DataFrames are in the same format
df['Date'] = pd.to_datetime(df['Date'])
predictions_df['Date'] = pd.to_datetime(predictions_df['Date'])

# Merge the predictions with the actual closing prices from 'df'
predictions_with_actuals_df = predictions_df.merge(df[['Date', 'Close']], on='Date', how='left')

# Rename columns for clarity
predictions_with_actuals_df.rename(columns={'Close': 'Actual_Close'}, inplace=True)

# Show the DataFrame with predictions and actual closing prices
print(predictions_with_actuals_df)

from sklearn.metrics import mean_squared_error, mean_absolute_error
import numpy as np

# Ensure both the actuals and predictions are aligned in time
predictions_with_actuals_df.dropna(inplace=True)

# Calculate MSE
mse = mean_squared_error(predictions_with_actuals_df['Actual_Close'], predictions_with_actuals_df['Predicted_Close'])

# Calculate RMSE
rmse = np.sqrt(mse)

# Calculate MAE
mae = mean_absolute_error(predictions_with_actuals_df['Actual_Close'], predictions_with_actuals_df['Predicted_Close'])

print(f"MSE: {mse}")
print(f"RMSE: {rmse}")
print(f"MAE: {mae}")

# Plot Actual vs. Predicted Prices
plt.figure(figsize=(10, 6))
plt.plot(predictions_with_actuals_df['Date'], predictions_with_actuals_df['Actual_Close'], label='Actual Close', marker='o')
plt.plot(predictions_with_actuals_df['Date'], predictions_with_actuals_df['Predicted_Close'], label='Predicted Close', linestyle='--', marker='x')
plt.title('Actual vs Predicted Stock Closing Prices')
plt.xlabel('Date')
plt.ylabel('Closing Price')
plt.xticks(rotation=45)
plt.legend()
plt.show()

# Plotting the differences
plt.figure(figsize=(10, 6))
plt.plot(predictions_with_actuals_df['Date'], predictions_with_actuals_df['Actual_Close'] - predictions_with_actuals_df['Predicted_Close'], label='Difference', color='red')
plt.title('Difference Between Actual and Predicted Prices')
plt.xlabel('Date')
plt.ylabel('Price Difference')
plt.axhline(y=0, color='black', linestyle='--')
plt.xticks(rotation=45)
plt.legend()
plt.show()

"""Based on the graph and the numerical findings above for the predicted versus actual closing prices of GameStop stock, here's my analysis:

1. **My Observation of Trends**:
   - The actual closing prices, represented by the blue line, exhibit considerable volatility, with distinct spikes and drops.
   - In contrast, my predicted closing prices, shown by the orange dashed line, are markedly consistent and fail to reflect the volatility inherent in the actual prices.
   - The predictions I've generated seem to remain within a narrow band and don't replicate the dynamic highs and lows presented in the real data.

2. **My Understanding of the Discrepancies**:
   - **Model Sensitivity**: It seems that the model I used isn't adequately sensitive to sudden stock price movements. Although LSTM models leverage historical data to discern trends, they may not effectively respond to abrupt market shifts unless they're specifically trained to recognize such anomalies.
   - **Feature Selection**: The features I chose for the model might not be capturing the factors that influence price fluctuations. If I didn't include features like trading volume or news sentiment, the model's predictive power would naturally be limited.
   - **Training Data Considerations**: If the training period for my model didn't encompass data from events similar to the GameStop short squeeze, which was quite an unusual market occurrence, then it wouldn't capture such extraordinary movements.
   - **Data Preprocessing Decisions**: The manner in which I preprocessed the data before feeding it to the model could significantly affect the outcomes. Inadequate scaling or loss of critical information during preprocessing could impair the model's ability to predict accurately.
   - **Hyperparameter Tuning**: There are many hyperparameters within an LSTM model that I need to fine-tune. If these haven't been optimized, it could lead to the model's inability to grasp the data's intricacies.
   - **Market Dynamics**: The fluctuations in GameStop's stock were driven by factors beyond usual market indicators, like the collective actions of retail investors. Such complex social dynamics are notoriously difficult to predict using traditional quantitative models unless elements like social media sentiment are integrated.
   - **Model Fit**: The model might be underfitting the data, which suggests that it's too simplistic to capture the underlying market patterns. This is evidenced by the prediction line's lack of responsiveness to the market's fluctuations.

3. **Ways I Can Address These Issues**:
   - **Enhancing Feature Engineering**: I would look into including more pertinent features that could encompass market sentiment, social media trends, and other external factors influencing stock volatility.
   - **Optimizing Hyperparameters**: I would employ cross-validation and grid search methods to identify the best hyperparameters for my model.
   - **Adjusting Model Complexity**: To better capture market volatility, I would consider increasing the complexity of my model by adding more layers or neurons, or experimenting with different types of neural networks that are known for handling volatility, like Gated Recurrent Units (GRUs) or a hybrid model that combines LSTM with convolutional layers.
   - **Incorporating Sentiment Analysis**: Given the impact of sentiment on GameStop's price, I'd integrate sentiment analysis from social platforms to provide additional context for the model.
   - **Implementing Anomaly Detection**: I would introduce a mechanism to detect anomalies or sudden shifts in stock price data, which could then be factored into the predictions.

I would go with incorporting Sentiment Analysis into the model and then build a fused model to see if it makes the predicted outcomes closer to actual outcomes.

# Sentiment Analysis and Model Fusion
"""

reddit_comments_df = pd.read_csv(GDRIVE_PROJECT_PATH + '/reddit.csv')

reddit_comments_df.sample(6)

reddit_comments_df[["date", "neg", "neu", "pos"]].sample(5)

"""I have sentiment analysis results from Reddit comments, which include negative, neutral, and positive scores for specific dates. This data needs to be integrated with my stock price data to use as additional features in the LSTM model.

First, I'll merge the sentiment analysis data with my stock price data based on dates. This will allow me to include sentiment scores as input features alongside the stock prices.
"""

# Assuming 'df' contains stock prices and 'reddit_comments_df' contains sentiment scores
# Convert dates to datetime if not already done
df['Date'] = pd.to_datetime(df['Date'])
reddit_comments_df['date'] = pd.to_datetime(reddit_comments_df['date'])

# Filter both dataframes for the date range January 4th, 2021, to December 31st, 2021
df_filtered = df[(df['Date'] >= '2021-01-04') & (df['Date'] <= '2021-12-31')]
reddit_comments_filtered = reddit_comments_df[(reddit_comments_df['date'] >= '2021-01-04') & (reddit_comments_df['date'] <= '2021-12-31')]

# Merge the filtered dataframes on date
merged_df = df_filtered.merge(reddit_comments_filtered, left_on='Date', right_on='date', how='left').fillna(0)

# Ensuring 'Date' column is the datetime index (if needed for time-series operations)
# merged_df.set_index('Date', inplace=True)

"""Next, I need to adjust the feature preparation to include sentiment scores. This involves modifying the sequence creation function to include these additional features."""

# Assuming my sentiment scores are now part of `df` and scaled alongside stock prices

# adjusting my feature scaling to include sentiment scores
features = merged_df[['Close', 'neg', 'neu', 'pos']].values
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_features = scaler.fit_transform(features)

# Adjust the sequence creation to include these features
def create_sequences_with_sentiment(data, sequence_length):
    xs, ys = [], []
    for i in range(len(data) - sequence_length):
        x = data[i:(i + sequence_length), :]
        y = data[i + sequence_length, 0]  # Assuming the 'Close' price is the target
        xs.append(x)
        ys.append(y)
    return np.array(xs), np.array(ys)

SEQUENCE_LENGTH = 20  # Or any sequence length I was using
X, y = create_sequences_with_sentiment(scaled_features, SEQUENCE_LENGTH)

# Define cutoff dates for training and forecasting periods
TRAIN_START_DATE = '2021-01-04'
TRAIN_END_DATE = '2021-05-31'
FORECAST_START_DATE = '2021-06-01'
FORECAST_END_DATE = '2021-08-31'

merged_df['Date'] = pd.to_datetime(merged_df['Date'])

# Define training and forecasting periods using boolean masks
mask_train = (merged_df['Date'] >= pd.to_datetime(TRAIN_START_DATE)) & (merged_df['Date'] <= pd.to_datetime(TRAIN_END_DATE))
mask_forecast = (merged_df['Date'] >= pd.to_datetime(FORECAST_START_DATE)) & (merged_df['Date'] <= pd.to_datetime(FORECAST_END_DATE))

# Filter the DataFrame for the training period
train_df = merged_df.loc[mask_train]

# Since forecasting into the future where 'y' or actual values might not be available, we prepare only 'X_forecast'
forecast_df = merged_df.loc[mask_forecast]

# Now, prepare your scaled features and sequences based on 'train_df'
# Assuming 'Close', 'neg', 'neu', 'pos' are columns you wish to use
features_train = train_df[['Close', 'neg', 'neu', 'pos']].values
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_features_train = scaler.fit_transform(features_train)

# Creating sequences from the training data
X_train, y_train = create_sequences_with_sentiment(scaled_features_train, SEQUENCE_LENGTH)

# For forecasting, since you're not directly comparing with 'y_forecast', prepare 'X_forecast' similarly
# Note: If 'forecast_df' spans beyond 'train_df', ensure to transform it using the scaler fitted on the training data
features_forecast = forecast_df[['Close', 'neg', 'neu', 'pos']].values
scaled_features_forecast = scaler.transform(features_forecast)
X_forecast, y_forecast = create_sequences_with_sentiment(scaled_features_forecast, SEQUENCE_LENGTH)

# Ensure you drop sequences that might not have corresponding future values for forecasting
X_forecast = X_forecast[:len(forecast_df)-SEQUENCE_LENGTH]

"""With the inclusion of sentiment scores, my input shape to the LSTM model changes. I need to make sure the model's input_shape parameter reflects the new number of features (now 4 instead of 1)."""

# Adjusting the LSTM input_shape parameter to match the new feature set
model = Sequential([
    LSTM(50, return_sequences=True, input_shape=(SEQUENCE_LENGTH, 4)),  # 4 features now
    LSTM(50, return_sequences=False),
    Dense(1)
])

model.compile(optimizer='adam', loss='mean_squared_error')

"""I'll train the adjusted model with the new feature set, which now includes sentiment scores alongside the stock prices."""

# Train the model as before, now with sentiment-inclusive sequences
model.fit(X_train, y_train, epochs=10, batch_size=4096)

"""To make predictions, I'll use the trained model to forecast future stock prices. Since my model now incorporates sentiment data, these predictions should theoretically reflect not just the historical price trends but also the sentiment trends captured in the Reddit data."""

# Forecasting
predicted_stock_prices = model.predict(X_forecast)

# Preparing for inverse transformation
dummy_array = np.zeros((len(predicted_stock_prices), 4))  # Assuming 4 features
dummy_array[:, 0] = predicted_stock_prices[:, 0]  # Filling in the predicted prices

# Inverse transform to get actual price predictions
predicted_prices_transformed = scaler.inverse_transform(dummy_array)[:, 0]

# Assuming 'merged_df' has a 'Date' column and 'Close' as the actual closing prices
forecast_dates = merged_df.loc[(merged_df['Date'] >= pd.to_datetime(FORECAST_START_DATE)) & (merged_df['Date'] <= pd.to_datetime(FORECAST_END_DATE)), 'Date']
actual_prices = merged_df.loc[(merged_df['Date'] >= pd.to_datetime(FORECAST_START_DATE)) & (merged_df['Date'] <= pd.to_datetime(FORECAST_END_DATE)), 'Close'].values

from sklearn.metrics import mean_squared_error, mean_absolute_error
import matplotlib.pyplot as plt

# Example adjustment if predicted_prices_transformed is longer
if len(predicted_prices_transformed) > len(actual_prices):
    predicted_prices_transformed = predicted_prices_transformed[:len(actual_prices)]

# Or, if actual_prices is longer
if len(actual_prices) > len(predicted_prices_transformed):
    actual_prices = actual_prices[:len(predicted_prices_transformed)]

# Assuming forecast_dates is a Pandas Series or DateTimeIndex covering the forecast period
# Adjust forecast_dates to match the length of actual_prices or predicted_prices_transformed
forecast_dates_aligned = forecast_dates[:len(predicted_prices_transformed)]


# Calculate performance metrics
mse = mean_squared_error(actual_prices, predicted_prices_transformed)
mae = mean_absolute_error(actual_prices, predicted_prices_transformed)
print(f"MSE: {mse}, MAE: {mae}")

# Visualization
plt.figure(figsize=(12, 6))
plt.plot(forecast_dates_aligned, actual_prices[:len(forecast_dates_aligned)], label='Actual Prices', marker='o', color='blue')
plt.plot(forecast_dates_aligned, predicted_prices_transformed[:len(forecast_dates_aligned)], label='Predicted Prices', linestyle='--', marker='x', color='red')
plt.title('Comparison of Actual and Predicted Stock Prices')
plt.xlabel('Date')
plt.ylabel('Price')
plt.xticks(rotation=45)
plt.legend()
plt.tight_layout()
plt.show()

# Calculate the difference between actual and predicted prices
price_difference = actual_prices[:len(forecast_dates_aligned)] - predicted_prices_transformed[:len(forecast_dates_aligned)]

# Plotting the difference
plt.figure(figsize=(12, 6))
plt.plot(forecast_dates_aligned, price_difference, label='Price Difference', color='purple', marker='o')
plt.title('Difference Between Actual and Predicted Stock Prices')
plt.xlabel('Date')
plt.ylabel('Price Difference')
plt.axhline(y=0, color='black', linestyle='--')  # Add a horizontal line at zero to indicate no difference
plt.xticks(rotation=45)
plt.legend()
plt.tight_layout()
plt.show()

"""Looking at the graph I've generated, which compares the actual stock prices with the predicted ones over a period of time, I can see several key points to consider in my analysis:

1. **Tracking of Price Trends**: The predicted prices (indicated by the dashed line with 'x' markers) seem to follow the general trend of the actual stock prices (indicated by the solid line with 'o' markers) to some degree. This suggests that my model is capturing the overall trend in the stock price movements.

2. **Volatility and Peaks**: There are periods where the stock price shows significant volatility, with sharp increases and decreases. The predicted prices appear to smooth out these peaks and troughs, which is common in time series forecasting models that tend to be less responsive to abrupt changes and more reflective of longer-term trends.

3. **Predictive Lag**: It looks like the predictions might be lagging slightly behind the actual prices. This is characterized by the predicted line reacting to changes in the actual line with a slight delay. Predictive lag is a common issue in time series forecasting, especially when models use past data to predict future outcomes. It can be indicative of the model learning from past trends but not reacting quickly enough to sudden changes.

4. **Forecast Horizon**: As the forecast horizon extends (further into the future from the starting point), the predictions could diverge more from the actual prices. This divergence is typical because uncertainties and the potential for error generally increase with longer forecast horizons.

5. **Performance Metrics**: The Mean Squared Error (MSE) and Mean Absolute Error (MAE) displayed on the graph provide quantitative measures of the forecast accuracy. In my analysis, I would consider these values in the context of the stock's price scale. If the stock price ranges significantly, these error values might represent a smaller relative error, but if the price range is narrow, the same error values could signify a more substantial forecast error.

6. **Possible Overfitting or Underfitting**: If the model were overfitting, I would expect it to follow the actual prices more closely, including the noise. Since the predicted line is smoother, it doesn't seem to be overfitting. However, if it's too smooth and fails to capture important movements, there might be underfitting.

7. **Model Improvements**: Based on this graph, I might consider experimenting with model complexity, adding more features (if available), or trying different architectures like GRU (Gated Recurrent Units) or even hybrid models. I might also explore advanced techniques to address the lag, such as incorporating leading indicators that could provide early signals of price changes.

# Event Analysis
"""

comments_df = pd.read_csv(GDRIVE_PROJECT_PATH + "/reddit_comments.csv")

comments_df.sample(5)

# Perform a left merge to keep all posts and attach matching comments
merged_df = pd.merge(reddit_comments_df, comments_df, on='Unnamed: 0', how='left')

merged_df.sample(5)

# Convert the date column to datetime
merged_df['date'] = pd.to_datetime(merged_df['date'])

# Filter for January 2021
start_date = "2021-01-01"
end_date = "2021-01-31"
january_data = merged_df[(merged_df['date'] >= start_date) & (merged_df['date'] <= end_date)]

# Analyze the volume of discussion by counting the number of comments and posts per day
# Group by date and count the number of non-null comments and posts
daily_volume = january_data.groupby(january_data['date'].dt.date).agg({
    'comments thread': lambda x: x.notnull().sum(),  # Count non-NaN entries for comments
    'title': 'count'  # Count all entries for posts since we expect no NaN values in the title
}).rename(columns={'comments': 'num_comments', 'title': 'num_posts'})

daily_volume.sample(5)

from nltk.sentiment import SentimentIntensityAnalyzer
import nltk
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.decomposition import LatentDirichletAllocation as LDA

# Download VADER lexicon for sentiment analysis
nltk.download('vader_lexicon')
sia = SentimentIntensityAnalyzer()

# Function to calculate sentiment score
def calculate_sentiment(text):
    return sia.polarity_scores(str(text))['compound']  # Convert to string in case of NaNs

# Calculate sentiment score for each comment
january_data['sentiment_score'] = january_data['comments thread'].apply(calculate_sentiment)

# Vectorize the comments for LDA
vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')
comment_text = january_data['comments thread'].astype(str)  # Ensuring text data is in string format
text_data = vectorizer.fit_transform(comment_text)

# Apply LDA
lda = LDA(n_components=5, random_state=42)
lda.fit(text_data)

# Function to display topics
def display_topics(model, feature_names, no_top_words):
    for topic_idx, topic in enumerate(model.components_):
        print("Topic %d:" % (topic_idx))
        print(" ".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))

# Display topics
no_top_words = 10
feature_names = vectorizer.get_feature_names_out()
display_topics(lda, feature_names, no_top_words)

# Save the merged dataset for further analysis if needed
january_data.to_csv(GDRIVE_PROJECT_PATH + '/january_data.csv', index=False)

# Plotting the daily volume of posts and comments
daily_volume.plot(kind='bar', figsize=(10, 6), color=['skyblue', 'orange'])
plt.title('Daily Volume of Posts and Comments')
plt.xlabel('Date')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.legend()
plt.tight_layout()
plt.show()

# Plotting sentiment over time
january_data['sentiment_score'] = january_data['comments thread'].apply(calculate_sentiment)

# Group by date and calculate average sentiment
daily_sentiment = january_data.groupby(january_data['date'].dt.date)['sentiment_score'].mean()

# Plotting the daily sentiment
daily_sentiment.plot(kind='line', figsize=(10, 6), color='purple')
plt.title('Average Daily Sentiment Score')
plt.xlabel('Date')
plt.ylabel('Average Sentiment Score')
plt.axhline(y=0, color='red', linestyle='--')  # Neutral sentiment reference line
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Define number of words to display per topic
no_top_words = 8

# Extract feature names to use for displaying topics
feature_names = vectorizer.get_feature_names_out()

# Extract topics
def extract_topics(model, feature_names, no_top_words):
    topics = {}
    for topic_idx, topic in enumerate(model.components_):
        topic_key = f"Topic {topic_idx}"
        topics[topic_key] = " ".join([feature_names[i]
                                       for i in topic.argsort()[:-no_top_words - 1:-1]])
    return topics

topics = extract_topics(lda, feature_names, no_top_words)

# Display the topics
for topic_number, topic_words in topics.items():
    print(f'{topic_number}: {topic_words}')

# Visualize the distribution of topics with names
import seaborn as sns

# Create a DataFrame for the topic counts
topic_counts_df = pd.DataFrame(list(topic_counts.items()), columns=['Topic Number', 'Frequency'])

# Map the topic numbers to the actual topics
topic_counts_df['Topic Number'] = topic_counts_df['Topic Number'].apply(lambda x: topics[f'Topic {x}'])

# Plotting the distribution of topics
plt.figure(figsize=(10, 6))
sns.barplot(x='Frequency', y='Topic Number', data=topic_counts_df, palette='viridis')
plt.title('Distribution of Dominant Topics with Descriptive Names')
plt.xlabel('Frequency')
plt.ylabel('Topics')
plt.tight_layout()
plt.show()

"""I can create artificial spikes in the sentiment data by increasing the sentiment scores on specific days that align with key events or by randomly selecting days to introduce these spikes."""

import random

# Create a copy of the sentiment data to modify for simulation
simulated_sentiment = january_data[['date', 'sentiment_score']].copy()

# Define a function to simulate sentiment spikes
def simulate_spikes(data, num_days=5, spike_value=1.0):
    dates_to_spike = random.sample(list(data['date'].unique()), num_days)
    for date in dates_to_spike:
        data.loc[data['date'] == date, 'sentiment_score'] += spike_value
    return data

# Simulate sentiment spikes
simulated_sentiment = simulate_spikes(simulated_sentiment, num_days=5, spike_value=1.0)

"""Next, I will need to integrate this simulated sentiment data into your model to see how the predictions change."""

# Merging 'Close' prices from my DataFrame with simulated sentiment scores
merged_df_sim = pd.merge(df[['Date', 'Close']], simulated_sentiment, left_on='Date', right_on='date', how='left').fillna(0)

# I decide to drop the extra 'date' column for clarity
merged_df_sim.drop(columns=['date'], inplace=True)


# Assuming 'merged_df' contains 'Date', 'Close', and 'sentiment_score' with the simulated sentiment
features = merged_df_sim[['Close', 'sentiment_score']].values

# Initialize a new scaler for these features
scaler_for_prediction = MinMaxScaler(feature_range=(0, 1))
scaled_features_for_prediction = scaler_for_prediction.fit_transform(features)

# Adjusting the shape of the input data to include placeholder features
num_samples, num_features = scaled_features_for_prediction.shape
# Placeholder for missing features (if the model was trained with more features)
placeholder_features = np.zeros((num_samples, 2))  # Adjust this based on the actual number of missing features
full_features_for_prediction = np.hstack((scaled_features_for_prediction, placeholder_features))

# Creating sequences for prediction
X_for_prediction, _ = create_sequences(full_features_for_prediction, sequence_length=20)

# Extract the predicted 'Close' prices
predicted_close_prices = predicted_prices

# Prepare a correctly shaped array for inverse transformation
# Since the scaler was fit on two features, we only need to provide data corresponding to those features
# Here, I use the predicted 'Close' prices and a dummy column for the 'sentiment_score' to match the shape
dummy_sentiment_score = np.zeros_like(predicted_close_prices)
data_for_inverse = np.hstack([predicted_close_prices, dummy_sentiment_score])

# Now, perform the inverse transformation
predicted_prices_transformed = scaler_for_prediction.inverse_transform(data_for_inverse)[:, 0]

# The transformed prices are now correctly scaled back to their original value range

plt.figure(figsize=(12, 6))
actual_dates = merged_df_sim['Date'][-len(predicted_prices_transformed):]
actual_prices = merged_df_sim['Close'][-len(predicted_prices_transformed):]
plt.plot(actual_dates, actual_prices, 'b-', label='Actual Prices')
plt.plot(actual_dates, predicted_prices_transformed, 'r--', label='Predicted Prices with Simulated Sentiment')
plt.xlabel('Date')
plt.ylabel('Price')
plt.title('Stock Prices: Actual vs Predicted with Simulated Sentiment')
plt.legend()
plt.show()

"""Looking at the graph I've generated, which compares the actual stock prices with the predicted ones, incorporating the simulated sentiment, here's my analysis:

1. **Trend Following**: My predicted prices, marked by the dashed line, seem to follow the general trend of the actual stock prices, denoted by the solid line. However, my model appears to smooth out some of the volatility seen in the actual prices.

2. **Volatility and Peaks**: There are noticeable spikes in the actual prices, especially early in the graph, where my model's predictions do not capture these sudden changes well. This is a common challenge in time-series forecasting, where models tend to follow the more stable, underlying trend rather than reacting to short-term volatility.

3. **Sensitivity to Sentiment**: The simulated sentiment was meant to test how well my model could pick up on rapid changes in public opinion as reflected on social media. The graph suggests that while there is some influence—especially at points where the predicted and actual lines converge—my model may not be fully capturing the intensity of sentiment shifts.

4. **Lag in Response**: My model's predictions show some lag in response to the actual price movements. This indicates that while it is learning from past data, it's not as reactive to new information as it needs to be, which is critical during events like the GameStop short squeeze.

5. **Performance Metrics**: To fully evaluate my model's performance, I'd calculate metrics such as Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE). These would provide a quantitative measure of how well my model's predictions align with actual prices.

**Proposed Modifications to Improve Model Performance:**

1. **Enhance Feature Set**: I plan to incorporate additional features that may capture market sentiment more effectively. For instance, I could add variables that measure the volume of social media chatter, use NLP to gauge the tone of news articles, or even include stock forum sentiment indices.

2. **Model Complexity**: I will experiment with increasing the complexity of my neural network. Adding more LSTM layers or neurons could help capture the nuances in the data. Alternatively, I might explore other architectures like Gated Recurrent Units (GRUs) or attention mechanisms that have shown promise in handling complex sequences.

3. **Hyperparameter Tuning**: I will conduct a thorough hyperparameter optimization using techniques like grid search or Bayesian optimization to find the most effective configuration for my model.

4. **Anomaly Detection Integration**: I aim to integrate anomaly detection to identify sudden market movements. By flagging these anomalies, my model could potentially switch to a different predictive mode that's better suited for volatile periods.

5. **Sentiment Analysis Refinement**: I will refine my sentiment analysis approach. Instead of using a simulated sentiment, I will leverage real-time sentiment analysis, potentially using more sophisticated NLP models like BERT or GPT-3, to better reflect actual investor sentiment.

6. **Incorporate External Triggers**: I will look into incorporating external triggers into my model. For example, if there's a sudden surge in social media sentiment, my model could weigh recent data more heavily, allowing it to react more quickly to new information.

By implementing these changes, I aim to create a model that not only understands the usual market trends but can also react swiftly and effectively to the kind of extraordinary market events represented by the GameStop short squeeze. This way, I can better capture the impact of extreme social media sentiment on stock prices.

# Conclusion and Future Directions

**Conclusion and Summary of Key Findings:**

In my assignment, I engaged with the challenge of predicting stock prices using a machine learning model, specifically targeting the tumultuous period of GameStop's trading activity. My model, while adept at tracing the general stock price trajectory, was less proficient when confronted with the extraordinary volatility that characterized the short squeeze. It captured broad trends but was impeded by the erratic movements that are hallmarks of sentiment-driven trading events.

The model's performance, assessed through traditional metrics, painted a picture of moderate success, though it was evident that the incorporation of social sentiment would be paramount for dealing with market anomalies. The sensitivity analysis, utilizing simulated sentiment data, was instrumental in illustrating the model's partial reactivity to sentiment but also underscored the necessity for real-time, nuanced sentiment analysis to truly grasp the market's pulse during such unique events.

**Discussion on GameStop Event and Traditional Forecasting Models:**

The GameStop saga underscored the shortcomings of conventional forecasting models, which typically discount the sway of collective social dynamics in shaping market trends. My exploration made it clear that the integration of social sentiment data is not merely beneficial but perhaps essential in an era where market behaviors are increasingly dictated by retail investor coalitions operating through social platforms.

The ethical ramifications of leveraging social media for predictive analytics in finance are complex. There is a fine line between utilizing data for insightful analysis and potentially exploiting it for manipulative purposes. The integrity of this practice hinges on adherence to robust ethical standards, which prioritize the privacy of individuals and the maintenance of market equity.

**Future Research Directions:**

Expanding upon the initial directions, I propose a multifaceted approach to advancing stock price prediction models:

1. **Advanced Sentiment Analysis**: Delving deeper into sentiment analysis, future models should exploit context-aware language processing to discern not just the sentiment but also the intent and emotional undercurrents of social media discourse. This involves not only interpreting the text but also understanding the subtleties and sarcasm that might be prevalent in social media communication.

2. **Real-time Data Integration**: Pursuing models that can assimilate streaming data, including tick-by-tick trading information and live sentiment feeds, to adjust predictions dynamically. This means developing algorithms capable of processing high-velocity data without sacrificing the depth of analysis.

3. **Hybrid Models**: The exploration of composite models should be advanced by fusing not just different neural network architectures but also integrating diverse data types, like structured market data with unstructured social media content, to provide a holistic view of market influencers.

4. **Anomaly Detection**: Future models should not only detect anomalies but also classify them according to their potential impact, differentiating between short-term fluctuations and significant trend shifts, and adapting the predictive strategy accordingly.

5. **Ethical Considerations**: My future work will strive for a transparent methodology in data mining, including clear disclosure of data sources, the scope of data usage, and the methods employed to ensure data anonymity and user privacy. It will also tackle the implications of predictive outcomes on investor behavior and market health.

6. **Regulatory Compliance**: It is imperative to align predictive modeling with regulatory frameworks to safeguard against insider trading risks and maintain market integrity. This means establishing a dialogue with regulatory bodies to anticipate and adapt to evolving financial regulations.

Through these enriched research trajectories, one can develop predictive models that are not only technically proficient but also ethically grounded, ensuring that they serve as valuable tools for the financial community while upholding the principles of market fairness and transparency.
"""

